{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd098e2-49c6-43df-9151-050694970b75",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 30px;\">**RAG 101 - Chat with Your Documents Using GPT & LangChain**</span>\n",
    "\n",
    "\n",
    "**Objectives:** \n",
    "- *Learn how to effectively load & store documents using LangChain*\n",
    "- *Build a retrieval augmented generation pipeline for querying data*\n",
    "- *Build a question-answering bot that answers questions based on your documents*\n",
    "\n",
    "You can learn more about the LangChain library in the following links:\n",
    "* [How to Make Large Language Models Play Nice with Your Software Using LangChain](https://www.kdnuggets.com/how-to-make-large-language-models-play-nice-with-your-software-using-langchain)\n",
    "* [6 Problems of LLMs That LangChain is Trying to Assess](https://www.kdnuggets.com/6-problems-of-llms-that-langchain-is-trying-to-assess)\n",
    "\n",
    "Let's start by understanding our main goal:\n",
    "\n",
    "First: \n",
    "- Take a set of PDFs. \n",
    "- Break them into pieces of texts. \n",
    "- Embed them into a vectorized representation. \n",
    "- Store them into a vector database. (FAISS, CHROMA, PINECONE...)\n",
    "- Once the vectors are persistend in the ddbb, we can get queries, embed them and find a similar chunk vectors. \n",
    "- The chunks are ranked according to how relevant they are to the question and are used to contextualize our LLM. \n",
    "\n",
    "**IMPORTANT:** The LLM doesn't really know what PDFs have. We take advantage of the LLM model to generate NLP answers and provide it with a question and a context to generate an accurate answer. \n",
    "\n",
    "![Structure_main](imgs/Structure_main.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42239f47-628c-4f50-aa9d-ee482177dd0c",
   "metadata": {},
   "source": [
    "# Install and Import the libraries\n",
    "\n",
    "We need to make sure our environment has the following packages: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7430d0f5-7341-464e-8d2e-c1f322edeb76",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 53044,
    "lastExecutedAt": 1709641405903,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "!pip install openai==0.27.1\n!pip install langchain==0.0.184\n!pip install tiktoken\n!pip install wikipedia\n!pip install pypdf\n!pip install faiss-cpu\n!pip install pinecone-client",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from tiktoken) (2025.9.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (4.56.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: requests in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: filelock in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pydantic<3,>=2.11 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (2.11.9)\n",
      "Collecting pydantic<3,>=2.11\n",
      "  Downloading pydantic-2.12.0-py3-none-any.whl (459 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m459.7/459.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic-settings<3,>=2.4 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (2.10.1)\n",
      "Collecting pydantic-settings<3,>=2.4\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.14.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pydantic<3,>=2.11) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pydantic<3,>=2.11) (0.7.0)\n",
      "Collecting pydantic-core==2.41.1\n",
      "  Downloading pydantic_core-2.41.1-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dotenv>=0.21.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pydantic-settings<3,>=2.4) (1.1.1)\n",
      "Installing collected packages: typing-inspection, pydantic-core, pydantic, pydantic-settings\n",
      "  Attempting uninstall: typing-inspection\n",
      "    Found existing installation: typing-inspection 0.4.1\n",
      "    Uninstalling typing-inspection-0.4.1:\n",
      "      Successfully uninstalled typing-inspection-0.4.1\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.33.2\n",
      "    Uninstalling pydantic_core-2.33.2:\n",
      "      Successfully uninstalled pydantic_core-2.33.2\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.11.9\n",
      "    Uninstalling pydantic-2.11.9:\n",
      "      Successfully uninstalled pydantic-2.11.9\n",
      "  Attempting uninstall: pydantic-settings\n",
      "    Found existing installation: pydantic-settings 2.10.1\n",
      "    Uninstalling pydantic-settings-2.10.1:\n",
      "      Successfully uninstalled pydantic-settings-2.10.1\n",
      "Successfully installed pydantic-2.12.0 pydantic-core-2.41.1 pydantic-settings-2.11.0 typing-inspection-0.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain<0.4,>=0.2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (0.3.76)\n",
      "Collecting langchain-core<0.4,>=0.2\n",
      "  Downloading langchain_core-0.3.78-py3-none-any.whl (449 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-community<0.4,>=0.2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (0.3.29)\n",
      "Collecting langchain-community<0.4,>=0.2\n",
      "  Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: langchain-pinecone>=0.2.8 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain<0.4,>=0.2) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain<0.4,>=0.2) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain<0.4,>=0.2) (2.32.5)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain<0.4,>=0.2) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain<0.4,>=0.2) (2.12.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain<0.4,>=0.2) (4.0.3)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain<0.4,>=0.2) (0.4.25)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-core<0.4,>=0.2) (24.2)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-community<0.4,>=0.2) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-community<0.4,>=0.2) (1.26.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-community<0.4,>=0.2) (0.6.7)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-community<0.4,>=0.2) (3.12.15)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-community<0.4,>=0.2) (2.11.0)\n",
      "Requirement already satisfied: pinecone[asyncio]<8.0.0,>=6.0.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-pinecone>=0.2.8) (7.3.0)\n",
      "Requirement already satisfied: simsimd>=5.9.11 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-pinecone>=0.2.8) (6.5.1)\n",
      "Requirement already satisfied: langchain-openai>=0.3.11 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-pinecone>=0.2.8) (0.3.32)\n",
      "Requirement already satisfied: httpx>=0.28.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-pinecone>=0.2.8) (0.28.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4,>=0.2) (0.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4,>=0.2) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4,>=0.2) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4,>=0.2) (6.6.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4,>=0.2) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4,>=0.2) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4,>=0.2) (1.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4,>=0.2) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4,>=0.2) (3.26.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from httpx>=0.28.0->langchain-pinecone>=0.2.8) (1.0.9)\n",
      "Requirement already satisfied: certifi in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from httpx>=0.28.0->langchain-pinecone>=0.2.8) (2025.8.3)\n",
      "Requirement already satisfied: idna in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from httpx>=0.28.0->langchain-pinecone>=0.2.8) (3.10)\n",
      "Requirement already satisfied: anyio in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from httpx>=0.28.0->langchain-pinecone>=0.2.8) (4.10.0)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.28.0->langchain-pinecone>=0.2.8) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<0.4,>=0.2) (3.0.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-openai>=0.3.11->langchain-pinecone>=0.2.8) (1.106.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langchain-openai>=0.3.11->langchain-pinecone>=0.2.8) (0.11.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain<0.4,>=0.2) (0.24.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain<0.4,>=0.2) (1.0.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain<0.4,>=0.2) (3.11.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone>=0.2.8) (2.5.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone>=0.2.8) (0.0.7)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone>=0.2.8) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone>=0.2.8) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohttp-retry<3.0.0,>=2.9.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone>=0.2.8) (2.9.1)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4,>=0.2) (2.41.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4,>=0.2) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4,>=0.2) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community<0.4,>=0.2) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.4,>=0.2) (3.4.3)\n",
      "Requirement already satisfied: sniffio in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai>=0.3.11->langchain-pinecone>=0.2.8) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai>=0.3.11->langchain-pinecone>=0.2.8) (0.10.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai>=0.3.11->langchain-pinecone>=0.2.8) (4.67.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai>=0.3.11->langchain-pinecone>=0.2.8) (1.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from anyio->httpx>=0.28.0->langchain-pinecone>=0.2.8) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from python-dateutil>=2.5.3->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone>=0.2.8) (1.17.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.3.11->langchain-pinecone>=0.2.8) (2025.9.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4,>=0.2) (1.1.0)\n",
      "Installing collected packages: langchain-core, langchain-community\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.76\n",
      "    Uninstalling langchain-core-0.3.76:\n",
      "      Successfully uninstalled langchain-core-0.3.76\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.29\n",
      "    Uninstalling langchain-community-0.3.29:\n",
      "      Successfully uninstalled langchain-community-0.3.29\n",
      "Successfully installed langchain-community-0.3.31 langchain-core-0.3.78\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: faiss-cpu in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: packaging in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pinecone in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (7.3.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone) (0.0.7)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone) (2025.8.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone) (4.15.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone) (2.5.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.5)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: wikipedia in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from wikipedia) (4.13.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from wikipedia) (2.32.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (4.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.8)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pypdf in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (6.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pypdf) (4.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-dotenv in /Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages (1.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# LLM LIBRARIES\n",
    "!pip install tiktoken\n",
    "!pip install transformers\n",
    "!pip install -U \"pydantic>=2.11,<3\" \"pydantic-settings>=2.4,<3\"\n",
    "!pip install -U \"langchain>=0.2,<0.4\" \"langchain-core>=0.2,<0.4\" \\\n",
    "               \"langchain-community>=0.2,<0.4\" \"langchain-pinecone>=0.2.8\"\n",
    "\n",
    "# VECTOR DATABASES\n",
    "!pip install faiss-cpu\n",
    "!pip install pinecone\n",
    "\n",
    "# AUXILIAR -> Deal with PDFs and get data online\n",
    "!pip install wikipedia\n",
    "!pip install pypdf\n",
    "\n",
    "# BASICS\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8360cb-c7a0-4976-8fe9-5482d14b4495",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1591,
    "lastExecutedAt": 1704816818752,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Basics\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom dotenv import load_dotenv\n\n# LangChain Training\n# LLM\nfrom langchain.llms import OpenAI\n\n# Document Loader\nfrom langchain.document_loaders import PyPDFLoader \n\n# Splitter\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter \n\n# Tokenizer\nfrom transformers import GPT2TokenizerFast  \n\n# Embedding\nfrom langchain.embeddings import OpenAIEmbeddings \n\n# Vector DataBase\nfrom langchain.vectorstores import FAISS, Pinecone # for the vector database part -- FAISS is local and temporal, Pinecone is cloud-based and permanent. \n\n# Chains\n#from langchain.chains.question_answering import load_qa_chain\n#from langchain.chains import ConversationalRetrievalChain"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/Users/josepferrersanchez/PRO/DataCamp/.venv/lib/python3.10/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "# Basics\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# OpenAI (LLM + embeddings) ‚Äî modern\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# Document loaders ‚Äî community package\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,            # single PDF\n",
    "    PyPDFDirectoryLoader,   # a folder of PDFs\n",
    "    WebBaseLoader,          # optional: web pages\n",
    ")\n",
    "\n",
    "# Splitters ‚Äî modern package (token-aware helpers available)\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Vector stores\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "# Pinecone (optional: cloud vector DB)\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Prompts & chains ‚Äî modern RAG APIs\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f578d5c",
   "metadata": {},
   "source": [
    "Before starting, make sure you have avaiable: \n",
    "- OpenAI API Key\n",
    "- Pinecone API Key and environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d70449-d284-43a6-ae31-df6e62ca1302",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 10,
    "lastExecutedAt": 1704816847276,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# We can directly upload our keys using a .env\n#load_dotenv()\n\nimport os\n\nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]\npinecone_api_key = os.environ[\"PINECONE_API_KEY\"]\npinecone_env_key = os.environ[\"PINECONE_ENV_KEY\"]\n\n# Alternatively, you can set the API keys as follows:\n#OPENAI_API_KEY   = \"sk-\"\n#PINECONE_API_KEY = \"34...\"\n#PINECONE_ENV_KEY = \"gcp-starter\""
   },
   "outputs": [],
   "source": [
    "# We can directly upload our keys using a .env\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "pinecone_api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "pinecone_env_key = os.environ[\"PINECONE_ENV_KEY\"]\n",
    "\n",
    "# Alternatively, you can set the API keys as follows:\n",
    "#OPENAI_API_KEY   = \"sk-\"\n",
    "#PINECONE_API_KEY = \"34...\"\n",
    "#PINECONE_ENV_KEY = \"gcp-starter\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a853ff5-0446-4f29-8e78-66fbe290c7f9",
   "metadata": {},
   "source": [
    "\n",
    "# PART 1: LANGCHAIN BASICS\n",
    "Langchain is a framework that helps us create complex applications using LLMs. \n",
    "\n",
    "üéØ **Objective:** Understand what is the LangChain library and all the elements that are required to generate a simple pipeline to query out documents. \n",
    "\n",
    "### **What is LangChain?**\n",
    "> LangChain is a framework for developing applications powered by language models.\n",
    "\n",
    "LangChain makes the hardest parts of working with AI models easier in two main ways:\n",
    "\n",
    "1. **Data-aware** - Bring external data, such as your files, other applications, and API data, to your LLMs\n",
    "2. **Agentic** - Allow your LLMs to interact with it's environment via decision making. Use LLMs to help decide which action to take next. \n",
    "\n",
    "### **Why LangChain?**\n",
    "1. **Components** - Abstractions for working with language models, along with a collection of implementations for each abstraction. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or not\n",
    "\n",
    "2. **Chains** - LangChain provides out of the box support for using and customizing 'chains' - a series of actions strung together. A structured assembly of components for accomplishing specific higher-level tasks.\n",
    "\n",
    "3. **Speed üö¢** - This team ships insanely fast. You'll be up to date with the latest LLM features.\n",
    "\n",
    "4. **Community üë•** - Wonderful discord and community support, meet ups, hackathons, etc.\n",
    "\n",
    "Though the usage of LLMs can be straightforward (text-in, text-out), when trying to build complex applications you'll quickly notice friction points. \n",
    "\n",
    "> LangChain helps with once you develop more complicated application and manage LLMs the way we want. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f548002-dda8-4d89-9c1e-7057392c11c5",
   "metadata": {},
   "source": [
    "## LangChain Components\n",
    "\n",
    "The LangChain library contains multiple elements to ease the process of building complex applications using LangChain.\n",
    "In this module we will focus mainly in 10 elements:\n",
    "\n",
    "**To load and process our documents**\n",
    "- Document Loaders\n",
    "- Text Splitters\n",
    "- Chat Messages *(Optional)*\n",
    "\n",
    "\n",
    "**To talk with our documents using NLP**\n",
    "- LLM model (GPT, Llama...)\n",
    "- Chains\n",
    "- Natural Language Retrieval\n",
    "- Metadata and Indexes\n",
    "- Memory *(Optional)*\n",
    "\n",
    "**Both Processes**\n",
    "- Text Embedding (OpenAI or Open-source models)\n",
    "- Vector Stores \n",
    "\n",
    "![Structure_basics](imgs/Structure_basics.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb81ae-fe1d-4108-a050-2e66c1bbf296",
   "metadata": {},
   "source": [
    "###  **The Model - Large Language Model of our choice**\n",
    "An AI-powered LLM that takes text in and responses text out. \n",
    "The default model is always ada-001, but we can explicitly choose the model of our preference. \n",
    "\n",
    "You can check the list of all avaialble models [here](https://platform.openai.com/docs/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c96d08-9a35-40f5-a248-f0cb74a842fc",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 4360,
    "lastExecutedAt": 1704817021400,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.llms import OpenAI\n\nchatgpt = OpenAI(\n                 model_name = \"gpt-3.5-turbo\", \n                 temperature= 0\n)\n\nprompt=\"Please, tell me some funny jokes\"\n\nprint(chatgpt(prompt))",
    "outputsMetadata": {
     "0": {
      "height": 521,
      "type": "stream"
     },
     "1": {
      "height": 437,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are a few jokes to brighten your day:\n",
      "\n",
      "1. Why don‚Äôt scientists trust atoms?\n",
      "   Because they make up everything!\n",
      "\n",
      "2. What do you call fake spaghetti?\n",
      "   An impasta!\n",
      "\n",
      "3. Why did the scarecrow win an award?\n",
      "   Because he was outstanding in his field!\n",
      "\n",
      "4. How does a penguin build its house?\n",
      "   Igloos it together!\n",
      "\n",
      "5. Why did the bicycle fall over?\n",
      "   Because it was two-tired!\n",
      "\n",
      "I hope these brought a smile to your face!\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain-openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0\n",
    "    )  # or \"gpt-4o\"\n",
    "prompt = \"Please, tell me some funny jokes\"\n",
    "print(chatgpt.invoke(prompt).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e039302b-02bb-499c-8637-f4be1bd2e34c",
   "metadata": {},
   "source": [
    "### **Chat Messages**\n",
    "LangChain allows us to segmentate prompts into three main types.(System, Human, AI)\n",
    "\n",
    "* **System** - Helpful background context that tell the AI its high-level behavior.\n",
    "* **Human** - Messages that represent the user input. \n",
    "* **AI** - Messages that show the response of the AI model, they work as examples to the model. \n",
    "\n",
    "\n",
    "For more, see OpenAI's [documentation](https://platform.openai.com/docs/guides/chat/introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6c86bf-542a-43f3-a1e7-221ed9bf6918",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 954,
    "lastExecutedAt": 1704817116502,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.chat_models import ChatOpenAI\nfrom langchain.schema import HumanMessage, SystemMessage, AIMessage\n\nchatgpt = ChatOpenAI(model_name = \"gpt-3.5-turbo\",\n                  temperature=0\n                 )\n\nhigh_level_behavior = \"\"\"\n                       You are an AI bot that help people decide where to travel. \n                       Always recommend three destination with a short sentence for each.\n                      \"\"\"\n\nresponse = chatgpt(\n    [\n        SystemMessage(content=high_level_behavior),\n        AIMessage(content=\"Hello! I am a traveller assistant, how can I help you?\"),\n        HumanMessage(content=\"Where should I travel next?\"),\n    ]\n)\n\nprint(response.content)",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     },
     "1": {
      "height": 57,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three great travel destinations for you to consider:\n",
      "\n",
      "1. **Kyoto, Japan** - Immerse yourself in the rich history and stunning temples of this ancient city, especially during cherry blossom season.\n",
      "2. **Santorini, Greece** - Enjoy breathtaking sunsets and picturesque white-washed buildings overlooking the Aegean Sea, perfect for a romantic getaway.\n",
      "3. **Machu Picchu, Peru** - Experience the awe-inspiring ruins of this Incan citadel, set high in the Andes, and hike the famous Inca Trail for an unforgettable adventure.\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain-openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage  # (AIMessage is returned, not sent)\n",
    "\n",
    "chatgpt = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "high_level_behavior = (\n",
    "    \"You are an AI bot that helps people decide where to travel. \"\n",
    "    \"Always recommend three destinations with a short sentence for each.\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=high_level_behavior),\n",
    "    HumanMessage(content=\"Where should I travel next?\"),\n",
    "]\n",
    "\n",
    "response = chatgpt.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab221be1-08fd-4942-b06e-5945cce7b148",
   "metadata": {},
   "source": [
    "You can also pass more chat history with responses from the AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035d9b68-ff7c-48fe-98e4-76961df7c480",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3077,
    "lastExecutedAt": 1704817121541,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "response = chatgpt(\n        [\n            SystemMessage(content=high_level_behavior),\n            AIMessage(content=\"Hello! I am a traveller assistant, how can I help you?\"),\n            HumanMessage(content=\"Where should I travel next?\"),\n            SystemMessage(content=\"What do you enjoy doing?\"),\n            HumanMessage(content=\"I love going to Museums?\"),\n        ]\n    )\n\nprint(response.content)",
    "outputsMetadata": {
     "0": {
      "height": 290,
      "type": "stream"
     },
     "1": {
      "height": 217,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three fantastic destinations for museum lovers:\n",
      "\n",
      "1. **Paris, France** - Home to the iconic Louvre and Mus√©e d'Orsay, Paris offers a rich tapestry of art and history in its world-renowned museums.\n",
      "\n",
      "2. **Washington, D.C., USA** - With the Smithsonian Institution's vast array of museums, including the National Gallery of Art and the National Museum of American History, there's something for everyone.\n",
      "\n",
      "3. **Berlin, Germany** - Explore the Museum Island, a UNESCO World Heritage site, featuring five incredible museums that showcase art, archaeology, and history from various eras.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "chatgpt = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are an AI bot that helps people decide where to travel. Always recommend three destinations with a short sentence for each.\"),\n",
    "    AIMessage(content=\"Hello! I am a travel assistant, how can I help you?\"),\n",
    "    HumanMessage(content=\"Where should I travel next?\"),\n",
    "    AIMessage(content=\"What do you enjoy doing?\"),\n",
    "    HumanMessage(content=\"I love visiting museums.\"),\n",
    "]\n",
    "\n",
    "response = chatgpt.invoke(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f2cdd-0466-423f-8984-45a5e54585af",
   "metadata": {},
   "source": [
    "### **Text Embedding Model**\n",
    "\n",
    "**In order to be able to process them, we can embed and convert string variables into vectors** (a series of numbers that hold the semantic 'meaning' of your text).\n",
    "\n",
    "Mainly used when comparing different pieces of text or when dealing with huge texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1df5db",
   "metadata": {},
   "source": [
    "![Vectors_1](imgs/Vectors_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9b4b36",
   "metadata": {},
   "source": [
    "![Vectors_2](imgs/Vectors_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3980f040-5612-4b0b-9a2d-3b9e3c8b2ba4",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 157,
    "lastExecutedAt": 1704817207570,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# 1. Import the embedding model\nfrom langchain.embeddings import OpenAIEmbeddings\n\n# 2. Create an instance of the model\nembeddings = OpenAIEmbeddings()\n\n# 3. Define a text to embed\ntext = \"This is a webinar!\"\n\n# 4. Embed the text\ntext_embedding = embeddings.embed_query(text)\n\nprint (f\"Your embedding is length {len(text_embedding)}\")\nprint (f\"Here's a sample: {text_embedding[:5]}...\")",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your embedding is length 1536\n",
      "Here's a sample: [-0.0483008474111557, 0.03188679739832878, -0.029621774330735207, 0.023959221318364143, -0.026297781616449356]...\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings  # not langchain.embeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # 1536-D\n",
    "\n",
    "text = \"This is an online crash course!\"\n",
    "vec = embeddings.embed_query(text)\n",
    "\n",
    "print(f\"Your embedding is length {len(vec)}\")\n",
    "print(f\"Here's a sample: {vec[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d5161-1b4c-48f6-b0b0-9604585178b7",
   "metadata": {},
   "source": [
    "### **Chains**\n",
    "\n",
    "Conversation chains in the context of Langchain are a concept involving the sequential linking of multiple conversational elements to build complex interactions. The idea is to streamline and enhance the conversation flow.\n",
    "\n",
    "The most basic chain is the `ConversationChain`.\n",
    "\n",
    "You can go check all available chains in the [LangChain Documentation.](https://python.langchain.com/docs/modules/chains/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "569cf2d8-d2df-4c63-8bd6-a37745686a13",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 412,
    "lastExecutedAt": 1704817272868,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.chains import ConversationChain\n\nconversation = ConversationChain(llm=chatgpt)\nconversation.run(\"Hello!\")\n\n#from langchain.chains.question_answering import load_qa_chain \n\n#chain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n#chain.run(input_documents = matches, question = enriched_query)"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How are you doing today? I'm here to chat about anything on your mind, whether it's a question, a topic of interest, or just some friendly banter. What would you like to talk about?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chatgpt, \n",
    "    memory=ConversationBufferMemory(return_messages=True))\n",
    "print(conversation.invoke({\"input\": \"Hello!\"})[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae7808-4897-4435-aa62-b29625f0c5aa",
   "metadata": {},
   "source": [
    "### Memory\n",
    "When interacting with a model, it is important to keep track of all interactions performed with it. \n",
    "\n",
    "To overcome these limitations, langchain implements different types of memories to use in your application.\n",
    "\n",
    "It is important to consider that storing all the interactions with the model can quickly escalate to a considerable amount of tokens to process every time we prompt the model. It is essential to bear in mind that ChatGPT has a token limit per interaction.\n",
    "\n",
    "You can learn more about memory [here]([https://towardsdatascience.com/custom-memory-for-chatgpt-api-artificial-intelligence-python-722d627d4d6d])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6dd11b7-b05e-435b-b8f2-27505a395c75",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 4966,
    "lastExecutedAt": 1704817328092,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.memory import ConversationSummaryBufferMemory\n\nmemory = ConversationSummaryBufferMemory(llm=chatgpt, max_token_limit=100)\n\nmemory.save_context({\"input\":  \"Can you recommend me where should I travel next?\"}, \n                    {\"output\": \"Hello! I am a traveller assistant, sure I can help you. What do you enjoy doing?\"})\n\nmemory.save_context({\"input\":  \"I love going to Museums\"}, \n                    {\"output\": \"Great then you should go to a cultural capital.\"})\n\nchatgpt = ChatOpenAI(model_name = \"gpt-3.5-turbo\",\n                  temperature=0\n                 )\n\nconversation = ConversationChain(\n    llm=chatgpt, \n    memory = memory,\n    verbose=True\n)\n\nconversation.run(\"What cities do you recommend me?\")",
    "outputsMetadata": {
     "0": {
      "height": 374,
      "type": "stream"
     },
     "1": {
      "height": 337,
      "type": "stream"
     },
     "2": {
      "height": 97,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Can you recommend where I should travel next?\n",
      "AI: Sure! What do you enjoy doing?\n",
      "Human: I love visiting museums.\n",
      "AI: Great‚Äîcultural capitals could be perfect.\n",
      "Human: What cities do you recommend?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There are several fantastic cities known for their museums! Here are a few recommendations:\n",
      "\n",
      "1. **Paris, France**: Home to the Louvre, which is the world's largest art museum, and the Mus√©e d'Orsay, known for its impressive collection of Impressionist and Post-Impressionist masterpieces. Don't forget the Centre Pompidou for modern art!\n",
      "\n",
      "2. **New York City, USA**: The Metropolitan Museum of Art is a must-visit, along with the Museum of Modern Art (MoMA) and the American Museum of Natural History. Each offers a unique experience and vast collections.\n",
      "\n",
      "3. **Rome, Italy**: The Vatican Museums are a highlight, featuring the Sistine Chapel and an extensive collection of art and historical artifacts. The Capitoline Museums and the Borghese Gallery are also worth exploring.\n",
      "\n",
      "4. **London, England**: The British Museum is famous for its vast collection of world art and artifacts, including the Rosetta Stone. The Tate Modern and the Natural History Museum are also excellent choices.\n",
      "\n",
      "5. **Berlin, Germany**: The Museum Island is a UNESCO World Heritage site and includes several important museums, such as the Pergamon Museum and the Neues Museum, which house incredible collections of ancient artifacts.\n",
      "\n",
      "6. **Amsterdam, Netherlands**: The Rijksmuseum is renowned for its Dutch Golden Age paintings, while the Van Gogh Museum showcases the largest collection of Van Gogh's works. The Anne Frank House offers a poignant historical perspective.\n",
      "\n",
      "Do any of these cities resonate with you?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chatgpt = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)   # main chat model\n",
    "memory = ConversationSummaryBufferMemory(llm=chatgpt, max_token_limit=100)  # summarizer uses same model\n",
    "\n",
    "# seed some context\n",
    "memory.save_context({\"input\": \"Can you recommend where I should travel next?\"},\n",
    "                    {\"output\": \"Sure! What do you enjoy doing?\"})\n",
    "memory.save_context({\"input\": \"I love visiting museums.\"},\n",
    "                    {\"output\": \"Great‚Äîcultural capitals could be perfect.\"})\n",
    "\n",
    "conversation = ConversationChain(llm=chatgpt, memory=memory, verbose=True)\n",
    "resp = conversation.invoke({\"input\": \"What cities do you recommend?\"})\n",
    "print(resp[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13e999f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human asks the AI for travel recommendations, expressing a love for visiting museums. The AI suggests that cultural capitals would be perfect and lists several cities known for their museums, including Paris, New York City, Rome, London, Berlin, and Amsterdam, highlighting key museums in each city. The AI then asks if any of these cities resonate with the human.\n"
     ]
    }
   ],
   "source": [
    "print(memory.moving_summary_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c27ca-2d99-45d1-9d64-3436d095765e",
   "metadata": {},
   "source": [
    "### Dealing with Documents\n",
    "\n",
    "We are here to deal with documents... so LangChain provides a wide variety of elements to deal with them. \n",
    "\n",
    "One of the most important improvements of LangChain is that it allows us to upload documents and pass them to our model. \n",
    "We consider a document as an object that holds a piece of text and metadata (more information about that text)\n",
    "\n",
    "- Document class\n",
    "- Document Loader\n",
    "- Document Retriever\n",
    "- Text Splitter\n",
    "- Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d33238-ce16-45fd-b216-1b9166341193",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13,
    "lastExecutedAt": 1704817584415,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# 1. Import the document class\nfrom langchain.schema import Document\n\n# 2. Define the document:\nDocument(\n         page_content=\"This is a dummy document\",\n         metadata={\n             'document_id' : 677,\n             'document_source' : \"mysource.pdf\",\n             'document_create_time' : \"01/06/2022\"\n                   })"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='This is a dummy document' metadata={'id': '677', 'source': 'mysource.pdf', 'created_at': '2022-06-01'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document  # modern import\n",
    "\n",
    "doc = Document(\n",
    "    page_content=\"This is a dummy document\",\n",
    "    metadata={\"id\": \"677\", \"source\": \n",
    "              \"mysource.pdf\", \n",
    "              \"created_at\": \"2022-06-01\"}\n",
    ")\n",
    "\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33e2ea-572e-4fbd-a348-5bcf0c961a8b",
   "metadata": {},
   "source": [
    "#### Document Loaders\n",
    "\n",
    "Depending on where our data is stored, we will need a different type of loader:\n",
    "\n",
    "- The **Online Loader** is used for loading a document directly from the Internet. LangChain implements different types of loaders. For example, there is the `WikipediaLoader` that helps you loading Wikipedia pages or the `HNLoader` to take content directly from any HackerNews page.\n",
    "\n",
    "\n",
    "\n",
    "- The **Offline Loader** is used loading a document stored that are already installed in your machine. There are also different types of offline loaders such as the **HTML** loader for `.html` pages or the **PyPDFLoader** for `.pdf` documents.\n",
    "\n",
    "In this tutorial, we will see an example of Online Loader by using the `WikipediaLoader` and the `HNLoader`, and an example of Offline Loader by using the PyPDFLoader.\n",
    "\n",
    "You can find a list of the supported [LangChain Document Loaders](https://python.langchain.com/docs/integrations/document_loaders) in the official documentation. Those Loaders are from external integrations, [native LangChain Loaders](https://python.langchain.com/docs/modules/data_connection/document_loaders/) can be found in the official documentation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2599ff89-9838-4341-91a9-424eb3c4a49d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 5701,
    "lastExecutedAt": 1704817696213,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.document_loaders import WikipediaLoader\n \n# Load content from Wikipedia using WikipediaLoader\nloader = WikipediaLoader(\"Machine_learning\")\nwikipedia_data = loader.load() #It returns a list of documents\n\nwikipedia_data[0]"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\n",
      "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\n",
      "Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.\n",
      "From a theoretical viewpoint, probably approximately correct learning provides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as empirical risk minimization under this framework.\n",
      "\n",
      "\n",
      "== History ==\n",
      "\n",
      "The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence. The synonym self-teaching computers was also used in this time period.\n",
      "The earliest machine learning program was introduced in the 1950s when Arthur Samuel invented a computer program that calculated the winning chance in checkers for each side, but the history of machine learning roots back to decades of human desire and effort to study human cognitive processes. In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells. Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data. Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.\n",
      "By the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognise patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions. A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981, a report was given on using teaching strategies so that an artificial neural network learns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.\n",
      "Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machin' metadata={'title': 'Machine learning', 'summary': 'Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\\nML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\\nStatistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.\\nFrom a theoretical viewpoint, probably approximately correct learning provides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as empirical risk minimization under this framework.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Machine_learning'}\n"
     ]
    }
   ],
   "source": [
    "# pip install wikipedia langchain-community\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "loader = WikipediaLoader(query=\"Machine learning\", lang=\"en\", load_max_docs=1, doc_content_chars_max=4000)\n",
    "wikipedia_data = loader.load()  # It returns a list of loaders\n",
    "\n",
    "print(wikipedia_data[0])  # a Document with .page_content and .metadata (e.g., source URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3dca600-e561-4654-b688-7cec585ae80d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1704817744183,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "print(\"\\nPage Content: \\n\", wikipedia_data[0].page_content)\nprint(\"\\nMeta Data: \\n\", wikipedia_data[0].metadata)",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Page Content: \n",
      " Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\n",
      "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\n",
      "Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.\n",
      "From a theoretical viewpoint, probably approximately correct learning provides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as empirical risk minimization under this framework.\n",
      "\n",
      "\n",
      "== History ==\n",
      "\n",
      "The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence. The synonym self-teaching computers was also used in this time period.\n",
      "The earliest machine learning program was introduced in the 1950s when Arthur Samuel invented a computer program that calculated the winning chance in checkers for each side, but the history of machine learning roots back to decades of human desire and effort to study human cognitive processes. In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells. Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data. Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.\n",
      "By the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognise patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions. A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification. Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973. In 1981, a report was given on using teaching strategies so that an artificial neural network learns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.\n",
      "Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\" This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machin\n",
      "\n",
      "Meta Data: \n",
      " {'title': 'Machine learning', 'summary': 'Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\\nML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\\nStatistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.\\nFrom a theoretical viewpoint, probably approximately correct learning provides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as empirical risk minimization under this framework.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Machine_learning'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPage Content: \\n\", wikipedia_data[0].page_content)\n",
    "print(\"\\nMeta Data: \\n\", wikipedia_data[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c5bc9d-5c18-4bb6-b30b-025da04e0862",
   "metadata": {},
   "source": [
    "Now we will repeat the previous procedure using `WebBaseLoader` and `PyPDFLoader`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56dfcf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain-community pypdf beautifulsoup4\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "# HN page\n",
    "hn_loader = WebBaseLoader(\"https://www.cnbc.com/2025/09/05/openai-is-building-an-ai-jobs-platform-that-could-rival-microsofts-linkedin.html\")\n",
    "hn_data = hn_loader.load()  # list[Document]\n",
    "\n",
    "# Single PDF\n",
    "pdf_loader = PyPDFLoader(\"docs/attentions.pdf\")\n",
    "pdf_data = pdf_loader.load()\n",
    "\n",
    "# Multiple PDFs (optional)\n",
    "# dir_loader = PyPDFDirectoryLoader(\"../docs\")\n",
    "# pdf_directory_data = dir_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b53bd0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Page Content: \n",
      " OpenAI is building an AI jobs platform that could challenge Microsoft‚Äôs LinkedInSkip NavigationMarketsPre-MarketsU.S. MarketsEurope MarketsChina MarketsAsia MarketsWorld MarketsCurrenciesCryptocurrencyFutures & CommoditiesBondsFunds & ETFsBusinessEconomyFinanceHealth & ScienceMediaReal EstateEnergyClimateTransportationIndustrialsRetailWealthSportsLifeSmall BusinessInvestingPersonal FinanceFintechFinancial AdvisorsOptions ActionETF StreetBuffett ArchiveEarningsTrader TalkTechCybersecurityAIEnterpriseInternetMediaMobileSocial MediaCNBC Disruptor 50Tech GuidePoliticsWhite HousePolicyDefenseCongressExpanding OpportunityEurope PoliticsChina PoliticsAsia PoliticsWorld PoliticsVideoLatest VideoFull EpisodesLivestreamTop VideoLive AudioEurope TVAsia TVCNBC PodcastsCEO InterviewsDigital OriginalsWatchlistInvesting ClubTrust PortfolioAnalysisTrade AlertsMeeting VideosHomestretchJim's ColumnsEducationSubscribePROPro NewsJosh BrownNEW!LivestreamFull EpisodesStock ScreenerMarket ForecastOptions InvestingChart InvestingStock ListsSubscribeLivestreamMenuMake ItselectUSAINTLLivestreamSearch quotes, news & videosLivestreamWatchlistSIGN INCreate free accountMarketsBusinessInvestingTechPoliticsVideoWatchlistInvesting ClubPROLivestreamMenuTechOpenAI is building an AI jobs platform that could challenge Microsoft‚Äôs LinkedInPublished Fri, Sep 5 20253:01 AM EDTUpdated Fri, Sep 5 20253:38 AM EDTDylan Butts@in/dylan-b-7a451a107WATCH LIVEKey PointsThe \"OpenAI Jobs Platform\" will utilize AI to help connect qualified job candidates to companies, which could put it in competition with LinkedIn.¬†OpenAI will also introduce a new certification program in connection with its \"OpenAI Academy.\"The certification program could also put it in competition with LinkedIn's learning platform.In this articleMSFTFollow your favorite stocksCREATE FREE ACCOUNTOpenAI CEO Sam Altman (L) attends a meeting of the White House Task Force on Artificial Intelligence Education in the East Room of the White House on September 04, 2025 in Washington, DC. Chip Somodevilla | Getty Images News | Getty ImagesOpenAI has announced it is developing an AI-centered jobs platform as part of broader efforts to expand AI literacy, and as the company grows its consumer and business-facing AI applications.The ChatGPT maker's \"OpenAI Jobs Platform\" will utilize AI to help connect qualified job candidates to companies, which could put it in competition with Microsoft's LinkedIn.¬†OpenAI and Microsoft have an uneasy partnership, with Microsoft formally labeling the AI startup as a competitor in search and news advertising in its annual filing last year. Microsoft is OpenAI's biggest investor, having reportedly poured $13 billion in the company.The news was announced by Fidji Simo, chief executive officer of applications and the former head of Instacart, in a blog post on Thursday.¬†\"Importantly, the jobs platform won't just be a way for big companies to attract more talent. It will have a track dedicated to helping local businesses compete, and local governments find the AI talent they need to better serve their constituents,\" Simo said.She didn't elaborate further on details regarding the platform, but a company spokesperson told TechCrunch that it expects to launch the service by mid-2026.¬†Additionally, OpenAI will introduce a new certification program in connection with its \"OpenAI Academy,\" an online learning platform that teaches workers how to use AI on the job better. This could also put it in competition with LinkedIn's learning platform, which also offers video courses across business, technology and creative fields, with certifications.\"[W]e're going to expand the Academy by offering certifications for different levels of AI fluency, from the basics of using AI at work all the way up to AI-custom jobs and prompt engineering,\" Simo said, adding that the program will utilize ChatGPT's Study mode. The study feature turns the chatbot into a teacher that questions, hints and provides feedback, instead of giving direct answers.watch nowVIDEO3:1403:14AI is eliminating jobs and climbing the corporate ladderTechCheckOrganizations will be able to make the certificate part of their own learning and development programs, with OpenAI already working with Walmart, the largest private employer in the U.S. OpenAI said it plans to certify 10 million Americans by 2030.The plans come amid fears about how AI is impacting the labor market. Business leaders like Salesforce's Marc Benioff have recently announced layoffs due to AI, while new studies have linked the technology to mass job loss for certain workers.¬†¬†Simo acknowledged the \"disruptive\" force of AI in her post, saying jobs and companies will look different and need to adapt.¬†\"[W]hat we can do is help more people become fluent in AI and connect them with companies that need their skills, to give people more economic opportunities.¬†Recent research from labor market data company Lightcast found that roles that require AI skills pay higher salaries on average than those that don't.¬†The new initiatives were also said to come as part of OpenAI's \"commitment to the White House's efforts toward expanding AI literacy.\"¬†The company has been strengthening ties with Washington, launching a new offering called OpenAI for Government on June 16, the same day it was awarded a contract of up to $200 million by the U.S. Department of Defense. OpenAI is also part of the $500 billion Stargate project, which aims to invest in AI infrastructure in the U.S. over the next four years.¬†OpenAI CEO Sam Altman was part of a group of tech leaders that met with U.S. President Donald Trump on Thursday to discuss topics including the development of artificial intelligence.¬†Before the dinner, first lady Melania Trump made a speech highlighting the importance of AI in education and American progress, but that \"we must manage AI's growth responsibly.\"Subscribe to CNBC PROSubscribe to Investing ClubLicensing & ReprintsCNBC CouncilsSupply Chain ValuesCNBC on PeacockJoin the CNBC PanelDigital ProductsNews ReleasesClosed CaptioningCorrectionsAbout CNBCInternshipsSite MapAd ChoicesCareersHelpContactNews TipsGot a confidential news tip? We want to hear from you.Get In TouchCNBC NewslettersSign up for free newsletters and get more CNBC delivered to your inboxSign Up NowGet this delivered to your inbox, and more info about our products and services.Advertise With UsPlease Contact UsPrivacy PolicyYour Privacy ChoicesCA NoticeTerms of Service¬© 2025 CNBC LLC. All Rights Reserved.¬†A Division of NBCUniversal\n",
      "      Data is a real-time snapshot *Data is delayed at least 15 minutes.\n",
      "      Global Business and Financial News, Stock Quotes, and Market Data\n",
      "      and Analysis.\n",
      "    Market Data Terms of Use and DisclaimersData also provided by\n",
      "\n",
      "Meta Data: \n",
      " {'source': 'https://www.cnbc.com/2025/09/05/openai-is-building-an-ai-jobs-platform-that-could-rival-microsofts-linkedin.html', 'title': 'OpenAI is building an AI jobs platform that could challenge Microsoft‚Äôs LinkedIn', 'description': 'OpenAI is developing an AI-centered jobs platform as part of broader efforts to expand AI literacy, and as the company expands in the application space.\\xa0', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPage Content: \\n\", hn_data[0].page_content)\n",
    "print(\"\\nMeta Data: \\n\", hn_data[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73dda01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Page Content: \n",
      " Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani‚àó\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer‚àó\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar‚àó\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit‚àó\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones‚àó\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez‚àó ‚Ä†\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "≈Åukasz Kaiser‚àó\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin‚àó ‚Ä°\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
      "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
      "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "‚àóEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\n",
      "has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\n",
      "attention and the parameter-free position representation and became the other person involved in nearly every\n",
      "detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\n",
      "tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\n",
      "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
      "implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\n",
      "our research.\n",
      "‚Ä†Work performed while at Google Brain.\n",
      "‚Ä°Work performed while at Google Research.\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n",
      "arXiv:1706.03762v7  [cs.CL]  2 Aug 2023\n",
      "\n",
      "Meta Data: \n",
      " {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-08-03T00:07:29+00:00', 'author': '', 'keywords': '', 'moddate': '2023-08-03T00:07:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'docs/attentions.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPage Content: \\n\", pdf_data[0].page_content)\n",
    "print(\"\\nMeta Data: \\n\", pdf_data[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29979d-f779-41e1-a35c-598770a03139",
   "metadata": {},
   "source": [
    "#### Text Splitter\n",
    "\n",
    "\n",
    "*Why we split at all*\n",
    "\n",
    "LLMs and embedding models have context limits; you can‚Äôt shove whole PDFs in.\n",
    "\n",
    "Smaller pieces (‚Äúchunks‚Äù) make retrieval more precise: you fetch only the relevant bits instead of whole pages.\n",
    "\n",
    "**Data Chunks and Model Tokenizer**\n",
    "\n",
    "##### Data Chunks (token-aware)\n",
    "To make documents usable by an LLM, we split them into smaller chunks. Chunk size strongly affects retrieval quality and cost.\n",
    "\n",
    "##### Tokenizer vs. embeddings\n",
    "A tokenizer converts text to tokens so models can process it, but we usually don‚Äôt manipulate tokens directly. Instead, we use a token-aware splitter so chunks align with model limits. The vector store then saves each chunk‚Äôs embedding vector (plus the original text/metadata)‚Äînot tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72a417e-7708-4d1e-bc99-0b0ba703dbe1",
   "metadata": {},
   "source": [
    "By using Langchain, we can highly customize how to split our data:\n",
    "- **Split by chunks**: The most general approach is to split your data into chunks of a concrete size. In the following example, we will take the data that we have already loaded (`wikipedia_data`, `hn_data` and `pdf_data`) and we will split it in portions of 200 characters. \n",
    "\n",
    "_What will happen if the split based on character count breaks a word?_\n",
    "\n",
    "There is the concept of \"chunk overlap\" that refers to a method where consecutive chunks of text share some common content. This technique is used to maintain context and coherence when a long document is divided into smaller parts due to the token limitations of LLMs. In this case, we will use a chunk size of 20 characters.\n",
    "\n",
    "So let's split the Wikipedia data we have just loaded: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a815007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia Data - Now you have 7 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",   # good default for GPT-3.5/4 families\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "wikipedia_chunks = text_splitter.split_documents(wikipedia_data)  # list[Document]\n",
    "print(f\"Wikipedia Data - Now you have {len(wikipedia_chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb800f3-0b01-4bff-9291-1736cb5cdbe4",
   "metadata": {},
   "source": [
    "Now we will replicate exactly the same for both `WebBaseLoader` and `PyPDFLoader`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d02e3b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Data - Now you have 62 chunks.\n",
      "Online HN - Now you have 9 chunks.\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain-text-splitters tiktoken\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Use OpenAI-compatible tokenization (no custom length_function needed)\n",
    "pdf_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=200, chunk_overlap=20\n",
    ")\n",
    "hn_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=200, chunk_overlap=20\n",
    ")\n",
    "\n",
    "pdf_chunks = pdf_splitter.split_documents(pdf_data)  # pdf_data: list[Document]\n",
    "print(f\"PDF Data - Now you have {len(pdf_chunks)} chunks.\")\n",
    "\n",
    "hn_chunks = hn_splitter.split_documents(hn_data)    # hn_data: list[Document]\n",
    "print(f\"Online HN - Now you have {len(hn_chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad447dd1-d5a5-4b2e-91ce-ef41539ddf73",
   "metadata": {},
   "source": [
    "We can make sure that the chunking has been successful by visualizing the distribution of chunk sizes. \n",
    "Since we have selected a chunk size of 200, the majority of our chunks should have this lenght:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31777cc6-9a05-45d6-b1b6-01db6587270c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 309,
    "lastExecutedAt": 1704818302589,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Quick data visualization to ensure chunking was successful\n\n# Create a list of token counts\ntoken_counts = [count_tokens(chunk.page_content) for chunk in pdf_chunks]\n\n# Create a DataFrame from the token counts\ndf = pd.DataFrame({'Token Count': token_counts})\n\n# Create a histogram of the token count distribution\ndf.hist(bins=40, )\n\n# Show the plot\nplt.show()"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     62.000000\n",
      "mean     168.580645\n",
      "std       39.967425\n",
      "min       24.000000\n",
      "50%      183.000000\n",
      "90%      194.000000\n",
      "95%      196.000000\n",
      "max      199.000000\n",
      "Name: token_count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pip install tiktoken pandas matplotlib\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Token counter (OpenAI models)\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(enc.encode(text or \"\", disallowed_special=()))\n",
    "\n",
    "# 2) Count tokens per chunk\n",
    "token_counts = [count_tokens(doc.page_content) for doc in pdf_chunks]  # pdf_chunks: list[Document]\n",
    "\n",
    "# 3) Quick look: stats + histogram\n",
    "df = pd.DataFrame({\"token_count\": token_counts})\n",
    "print(df[\"token_count\"].describe(percentiles=[0.5, 0.9, 0.95]))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df[\"token_count\"], bins=40)\n",
    "plt.xlabel(\"Tokens per chunk\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"PDF chunk token distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c149bde7-39f5-4912-83f2-fb238e4d72a7",
   "metadata": {},
   "source": [
    "- **Split by pages**: If your data comes from documents organized in pages, there are methods that allow you to split data in pages to keep track of the page content. This method is specially useful when dealing with PDFs, as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87a8e84c-d658-4a7a-8144-d84fcb169928",
   "metadata": {
    "executionCancelledAt": 1704727738639,
    "executionTime": 1063,
    "lastExecutedAt": 1704708532500,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Simple method - Split by pages    ________________________________________________________________________\n# You need a PDF file in your environement. \nloader = PyPDFLoader(\"Docs/attentions.pdf\")\npdf_pages_chunks = loader.load_and_split()\npdf_pages_chunks\n\nprint(\"\\nSPLITTING BY PAGES\")\nprint(\"PDF Splited by Pages - You have {0} number of chunks.\".format(len(pdf_pages_chunks)))",
    "outputsMetadata": {
     "0": {
      "height": 77,
      "type": "stream"
     },
     "1": {
      "height": 57,
      "type": "stream"
     },
     "2": {
      "height": 137,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPLITTING BY PAGES\n",
      "PDF split by pages ‚Äî you have 15 chunks.\n"
     ]
    }
   ],
   "source": [
    "# pip install -U langchain-community pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# A) Truly split by pages (recommended given your print message)\n",
    "loader = PyPDFLoader(\"docs/attentions.pdf\")\n",
    "pdf_pages = loader.load()  # one Document per page\n",
    "\n",
    "print(\"\\nSPLITTING BY PAGES\")\n",
    "print(f\"PDF split by pages ‚Äî you have {len(pdf_pages)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06933573-24eb-4ba2-bf05-4410912be27e",
   "metadata": {},
   "source": [
    "### Vector Stores\n",
    "\n",
    "Vector stores, also known as vector databases, are specialized types of databases designed to efficiently handle and manipulate high-dimensional vector data. In our case, we will store the tokenized and splitted content, e.g., the data chunks in the format that LLMs can process.\n",
    "\n",
    "There are different types of vector stores. Depending on the storage of the data, we can classify them as:\n",
    "- **Local Vector Stores**: This type of databases store the information in your local system. As an example of Local Vector Store, we will use FAISS.\n",
    "- **Online Vector Stores**: This type of databases store the information in the cloud. We will use Pinecone as out preferred option for Online Vector Stores.\n",
    "\n",
    "FAISS - EXAMPLE OF LOCAL VECTOR STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7dc17d0-275f-4376-86e1-11661a2dd1ef",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 4673,
    "lastExecutedAt": 1704818404491,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.vectorstores import FAISS  # for the vector database part -- FAISS is local and temporal, Pinecone is cloud-\nfrom langchain.embeddings.openai import OpenAIEmbeddings\n\n# Get embedding model\nembeddings = OpenAIEmbeddings()\n\n# OPTION 1: FAISS (Facebook AI Similarity Search) Local _______________________________________________________________________________________\n# Create vector database\ndb_FAISS = FAISS.from_documents(pdf_chunks, embeddings)",
    "outputsMetadata": {
     "0": {
      "height": 580,
      "type": "stream"
     },
     "1": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5h/h364vcws335c872gj8pv3jvm0000gn/T/ipykernel_2804/2279994550.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS  # for the vector database part -- FAISS is local and temporal, Pinecone is cloud-\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Get embedding model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# OPTION 1: FAISS (Facebook AI Similarity Search) Local _______________________________________________________________________________________\n",
    "# Create vector database\n",
    "db_FAISS = FAISS.from_documents(pdf_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4faca6-6ae9-453c-90d0-b31fc75a7872",
   "metadata": {},
   "source": [
    "PINECONE - EXAMPLE OF ONLINE VECTOR STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "776ae3bd-a6d2-4066-881a-dd08cc9f9ede",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2496,
    "lastExecutedAt": 1704818462367,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pinecone  #We need the Pinecone library to initialize our connection.\nfrom langchain.vectorstores import Pinecone # for the vector database part -- Pinecone is cloud-\n# OPTION 2: PINECONE Online\n     \n# We initialize pinecone\npinecone.init(      \n\tapi_key=os.getenv(\"PINECONE_API_KEY\"),      \n\tenvironment=os.getenv(\"PINECONE_ENV_KEY\")     \n) \n\n# Create a new pinecone index\n#pinecone.create(name=\"langchain\", dimension=1536, metric=\"cosine\")\n\n# We define the name of our index (in case the index is already created)\nindex_name = \"langchain\"\n\n# The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`. We use the Pinecone library of LangChain\ndb_Pinecone = Pinecone.from_documents(pdf_chunks, embeddings, index_name=index_name)"
   },
   "outputs": [],
   "source": [
    "# pip install -U pinecone langchain-pinecone\n",
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "\n",
    "index_name = \"datacamp-rag-tutorial\"\n",
    "\n",
    "if index_name not in [i.name for i in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,                 # match your embeddings model (e.g., OpenAI text-embedding-3-small = 1536)\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")  # pick your region\n",
    "    )\n",
    "\n",
    "# Build / upsert with LangChain\n",
    "db_Pinecone = PineconeVectorStore.from_documents(\n",
    "    documents=pdf_chunks,              # your list[Document]\n",
    "    embedding=embeddings,              # your embeddings object\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6151d-08d3-4c8f-8a7a-643c101bd701",
   "metadata": {},
   "source": [
    "### Natural Language Retrieval\n",
    "We first start performing a semantic search within our Vector DataBase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b8ba0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "db = FAISS.from_documents(pdf_chunks, embeddings)  # pdf_chunks: list[Document]\n",
    "matches = db.similarity_search(\"List all authors of 'Attention Is All You Need'\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0be901c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "Ashish Vaswani‚àó\n",
      "Google Brain\n",
      "avaswani@google.com\n",
      "Noam Shazeer‚àó\n",
      "Google Brain\n",
      "noam@google.com\n",
      "Niki Parmar‚àó\n",
      "Google Research\n",
      "nikip@google.com\n",
      "Jakob Uszkoreit‚àó\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones‚àó\n",
      "Google Research\n",
      "llion@google.com\n",
      "Aidan N. Gomez‚àó ‚Ä†\n",
      "University of Toronto\n",
      "aidan@cs.toronto.edu\n",
      "≈Åukasz Kaiser‚àó\n",
      "Google Brain\n",
      "lukaszkaiser@google.com\n",
      "Illia Polosukhin‚àó ‚Ä°\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-08-03T00:07:29+00:00', 'author': '', 'keywords': '', 'moddate': '2023-08-03T00:07:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'docs/attentions.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1', 'text': 'Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani‚àó\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer‚àó\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar‚àó\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit‚àó\\nGoogle Research\\nusz@google.com\\nLlion Jones‚àó\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez‚àó ‚Ä†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\n≈Åukasz Kaiser‚àó\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin‚àó ‚Ä°\\nillia.polosukhin@gmail.com\\nAbstract'}\n"
     ]
    }
   ],
   "source": [
    "print(matches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b2b23d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='<EOS>\n",
      "<pad>\n",
      "The\n",
      "Law\n",
      "will\n",
      "never\n",
      "be\n",
      "perfect\n",
      ",\n",
      "but\n",
      "its\n",
      "application\n",
      "should\n",
      "be\n",
      "just\n",
      "-\n",
      "this\n",
      "is\n",
      "what\n",
      "we\n",
      "are\n",
      "missing\n",
      ",\n",
      "in\n",
      "my\n",
      "opinion\n",
      ".\n",
      "<EOS>\n",
      "<pad>\n",
      "Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\n",
      "Full attentions for head 5. Bottom: Isolated attentions from just the word ‚Äòits‚Äô for attention heads 5\n",
      "and 6. Note that the attentions are very sharp for this word.\n",
      "14' metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-08-03T00:07:29+00:00', 'author': '', 'keywords': '', 'moddate': '2023-08-03T00:07:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'docs/attentions.pdf', 'total_pages': 15, 'page': 13, 'page_label': '14', 'text': '<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‚Äòits‚Äô for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14'}\n"
     ]
    }
   ],
   "source": [
    "print(matches[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17489dca-2a53-40ab-9b12-13a65e1f8c53",
   "metadata": {},
   "source": [
    "In the above section, we have seen how to retrieve the coincidences of you query in the documents in our vector store. Nevertheless, the output is a bit difficult to read. We can leverage the usage of LLMs by feeding the coincidences in our vector store to an LLM and let it generate a response in Natural Language using the additional information from our documents. We can do so by using the so-called **[LangChain Chains](https://python.langchain.com/docs/expression_language/get_started)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccc9684f-f666-473f-8a48-9c8f53e413ab",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2981,
    "lastExecutedAt": 1704818563496,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# ONLINE - PINECONE\n\n# 1. Define our query of interest. \nquery = \"Can you please tell me all the autors of the article Attention is all you need?\"\n\n# 2. Perform the semantic search in our vector database with the similarity_search command.  \nmatches = db_Pinecone.similarity_search(query, k=2)\n\n# 3. Define a load_qa_chain.\nchain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n\n# 4. Execute the chain with the prompt and the matches. \nchain.run(input_documents=matches, question = query)",
    "outputsMetadata": {
     "0": {
      "height": 257,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors of the paper \"Attention Is All You Need\" are:\n",
      "\n",
      "1. Ashish Vaswani\n",
      "2. Noam Shazeer\n",
      "3. Niki Parmar\n",
      "4. Jakob Uszkoreit\n",
      "5. Llion Jones\n",
      "6. Aidan N. Gomez\n",
      "7. ≈Åukasz Kaiser\n",
      "8. Illia Polosukhin\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "# 1- WE DEFINE OUR QUERY\n",
    "query = \"List all authors of the paper 'Attention Is All You Need'.\"\n",
    "\n",
    "# 2- WE PERFORM A SEMANTIC SEARCH IN OUR VECTOR DATABASE\n",
    "matches = db_Pinecone.similarity_search(query, k=2)\n",
    "\n",
    "# 3 - WE GENERATE A RAG PIPELINE BY SENDING THESE MATCHES TO AN LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Use ONLY the context to answer. If not in context, say you don't know.\\n\\n{context}\\n\\nQuestion: {input}\"\n",
    ")\n",
    "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retriever = db_Pinecone.as_retriever(search_type=\"similarity\", k=4)  # or search_type=\"mmr\"\n",
    "rag = create_retrieval_chain(retriever, doc_chain)\n",
    "\n",
    "# 4 - WE INVOKE THE RETRIEVER\n",
    "resp = rag.invoke({\"input\": query})\n",
    "print(resp[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812cbc3f-2d98-4085-8fa4-827cf7589e24",
   "metadata": {},
   "source": [
    "Now we can replicate the same using `FAISS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d164cac5-2244-4582-b567-e9ae4461afdd",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2611,
    "lastExecutedAt": 1704818697699,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# LOCAL - FAISS\nfrom langchain.chains.question_answering import load_qa_chain \n\n# The OpenAI embedding model `text-embedding-ada-002 uses 1536 dimensions`\ndb_FAISS = FAISS.from_documents(pdf_chunks, embeddings)\n\n# We can define how many similarities we want to get back by defining the variable k\nquery = \"Can you please tell me all the autors of the article Attention is all you need?\"\nmatches = db_FAISS.similarity_search(query, k=4)\n\nchain = load_qa_chain(chatgpt, chain_type=\"stuff\")\nchain.run(input_documents=matches, question = query)\n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors of the paper \"Attention Is All You Need\" are:\n",
      "\n",
      "1. Ashish Vaswani\n",
      "2. Noam Shazeer\n",
      "3. Niki Parmar\n",
      "4. Jakob Uszkoreit\n",
      "5. Llion Jones\n",
      "6. Aidan N. Gomez\n",
      "7. ≈Åukasz Kaiser\n",
      "8. Illia Polosukhin\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 1- WE DEFINE OUR QUERY\n",
    "query = \"List all authors of the paper 'Attention Is All You Need'.\"\n",
    "\n",
    "# 2- WE PERFORM A SEMANTIC SEARCH IN OUR VECTOR DATABASE\n",
    "db = FAISS.from_documents(pdf_chunks, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", k=2)\n",
    "\n",
    "# LLM + prompt\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Use the context to answer the question.\\n\\n{context}\\n\\nQuestion: {input}\"\n",
    ")\n",
    "# 3 - WE GENERATE A RAG PIPELINE BY SENDING THESE MATCHES TO AN LLM\n",
    "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag = create_retrieval_chain(retriever, doc_chain)\n",
    "\n",
    "# 4 - WE INVOKE THE RETRIEVER\n",
    "resp = rag.invoke({\"input\": query})\n",
    "print(resp[\"answer\"])              # final answer\n",
    "# print(resp[\"context\"])           # the retrieved Documents (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad7d06-178b-467b-979b-8976582012a7",
   "metadata": {},
   "source": [
    "### Indexes and Metadata\n",
    "When we upload data to our vector database, there is metadata that allows us to understand where the data is coming from. \n",
    "When dealing with PDFs, the source information allows us to know what pdf and page the info is coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97d1db0b-b343-4836-b43b-8e4ab735c033",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 174,
    "lastExecutedAt": 1704818705089,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#from langchain.embeddings import OpenAIEmbeddings\n#from langchain.indexes import index\n\nquery = \"Who created transformers?\"\nmatches = db_FAISS.similarity_search(query)\n\nprint(\"______________________________________ THIRD MATCH\")\n\nprint(\"We can get the chunk text content and get: \\n\", matches[3].page_content)\nprint(\"\\nWe can get the chunk metadata and get: \\n\", matches[3].metadata)\nprint(\"\\nThe source of our match is: \\n\" , matches[3].metadata[\"source\"], \"and page\", matches[3].metadata[\"page\"])",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________ THIRD MATCH\n",
      "We can get the chunk text content and get: \n",
      " significant improvements in computational efficiency through factorization tricks [21] and conditional\n",
      "computation [32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
      "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
      "2 Background\n",
      "\n",
      "We can get the chunk metadata and get: \n",
      " {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-08-03T00:07:29+00:00', 'author': '', 'keywords': '', 'moddate': '2023-08-03T00:07:29+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'docs/attentions.pdf', 'total_pages': 15, 'page': 1, 'page_label': '2'}\n",
      "\n",
      "The source of our match is: \n",
      " docs/attentions.pdf and page 1\n"
     ]
    }
   ],
   "source": [
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "#from langchain.indexes import index\n",
    "\n",
    "query = \"Who created transformers?\"\n",
    "matches = db_FAISS.similarity_search(query)\n",
    "\n",
    "print(\"______________________________________ THIRD MATCH\")\n",
    "\n",
    "print(\"We can get the chunk text content and get: \\n\", matches[3].page_content)\n",
    "print(\"\\nWe can get the chunk metadata and get: \\n\", matches[3].metadata)\n",
    "print(\"\\nThe source of our match is: \\n\" , matches[3].metadata[\"source\"], \"and page\", matches[3].metadata[\"page\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5f032-6e4d-40b2-b851-ccb9c86fc097",
   "metadata": {},
   "source": [
    "Now it is the time to put it all together and generate a simple pipeline to query our documents using a LLM model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a986b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def ensure_meta(doc: Document) -> Document:\n",
    "    m = doc.metadata\n",
    "    # guarantee keys exist and are JSON-safe\n",
    "    m[\"source\"] = str(m.get(\"source\") or m.get(\"file_path\") or m.get(\"url\") or \"unknown\")\n",
    "    m[\"page\"] = m.get(\"page\", \"N/A\")\n",
    "    # optional: prebuilt citation for prompts / UI\n",
    "    page_disp = (m[\"page\"] + 1) if isinstance(m[\"page\"], int) else m[\"page\"]\n",
    "    m[\"citation\"] = f\"{Path(m['source']).name} ‚Ä¢ p.{page_disp}\"\n",
    "    doc.metadata = m\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0282a5-73c9-44b8-87fd-eb175d676748",
   "metadata": {},
   "source": [
    "# PART 2: Loading and processing our documents\n",
    "\n",
    "\n",
    "\n",
    "PyPDFDirectoryLoader allows us to upload multiple PDFs at once. In our case, we have two PDFs in the Docs directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db047f-2475-4738-a726-458a5799a21e",
   "metadata": {},
   "source": [
    "## **STEP 1 - LOADER**\n",
    "\n",
    "Use the `PDFDirectoryLoader` to upload all PDFs contained within the the Docs folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a374a538-47c8-4679-a5d6-6c3e4a8a208c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 13294,
    "lastExecutedAt": 1704818828591,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#STEP 1 - LOADER\nfrom langchain.document_loaders import PyPDFDirectoryLoader\n\nloader = PyPDFDirectoryLoader(\"Docs/\")\n\ndata = loader.load()"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 101 page-docs from docs\n"
     ]
    }
   ],
   "source": [
    "#STEP 1 - LOADER\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"docs\")\n",
    "pdf_pages = loader.load()                         # list[Document], one per page\n",
    "pdf_pages = [ensure_meta(d) for d in pdf_pages]\n",
    "print(f\"Loaded {len(pdf_pages)} page-docs from docs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aebdc5-1686-4401-89d2-3b59546f8d3c",
   "metadata": {},
   "source": [
    "## **STEP 2 - CHUNKING**\n",
    "\n",
    "Generate the chunks for the PDFs contained in the directory. \n",
    "1. Import both RecursiveCharacterTextSplitter from langchain.text_splitter and GPT2TokenizerFast from transformers. \n",
    "2. Define a tokenizer with the following command: tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "3. Define a count_tokens function that will allow us to count the tokens of out text. \n",
    "4. Define the text_splitter with a chunk_size of 200, a chunk_overlap of 20 and the length_function we have just defined. \n",
    "5. Apply the command `.split_documents`to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "198312a1-bd33-4922-b5fd-1e402cd10c91",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1378,
    "lastExecutedAt": 1704818978129,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#STEP 2 - CHUNKING OUR DATA\n#_____________________________________________________________________PDFs Data\n# 1 - Splitter\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter \n\n# 2 - Tokenizer\nfrom transformers import GPT2TokenizerFast \n\n# 3 - Create function to count tokens\ntokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n\ndef count_tokens(text: str) -> int:\n    return len(tokenizer.encode(text))\n\n# 4 - Define the splitter\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size      = 200, \n    chunk_overlap   = 20,\n    length_function = count_tokens # It uses len() by default. \n)\n\n# 5 - Apply the .split_document command\nchunks = text_splitter.split_documents(data)\nprint(\"Multiple PDFs - Now you have {0} number of chunks.\".format(len(chunks)))",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     },
     "1": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 101 page-docs; produced 584 chunks.\n"
     ]
    }
   ],
   "source": [
    "#STEP 2 - CHUNKING OUR DATA\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\", chunk_size=200, chunk_overlap=20\n",
    ")\n",
    "pdf_chunks = splitter.split_documents(pdf_pages)\n",
    "pdf_chunks = [ensure_meta(d) for d in pdf_chunks]   # <- this is the list you'll embed\n",
    "print(f\"Loaded {len(pdf_pages)} page-docs; produced {len(pdf_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f548885-aee9-4b4a-bf1d-e996ed02c74d",
   "metadata": {},
   "source": [
    "## **STEP 3 - EMBEDD AND UPLOAD THE DATA INTO A VECTORSTORE**\n",
    "\n",
    "**TASK**\n",
    "- Upload the data into the FAISS vector store using the `from_documents`command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04a6a94c-153d-438a-978b-df189a33fa6c",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 4211,
    "lastExecutedAt": 1704819033112,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# STEP 3 - EMBEDDING AND UPLOAD DATA INTO OUR VECTORSTORE\n\n# ___________________________________________________________________________ LOCAL VERSION\n\n# 1. Create vector database with FAISS\ndb_FAISS = FAISS.from_documents(chunks, embeddings)\n\n# Check similarity search is working\nquery = \"Who created transformers?\"\nmatches = db_FAISS.similarity_search(query)\nprint(\"We found {0} number of similarities.\".format(len(matches)))\nfor match in matches:\n    print(\"\\n\", match.page_content)",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 3 similarities.\n",
      "\n",
      "[1] codex.pdf ‚Ä¢ p.16\n",
      "training of deep bidirectional transformers for language under-\n",
      "standing. arXiv preprint arXiv:1810.04805, 2018.\n",
      "Dhariwal, P., Jun, H., Payne, C., Kim, J. W., Radford, A., and\n",
      "Sutskever, I. Jukebox: A generative model for music. arXiv\n",
      "preprint arXiv:2005.00341, 2020.\n",
      "Drain, D., Wu, C., Svyatkovskiy, ...\n",
      "\n",
      "[2] attentions.pdf ‚Ä¢ p.1\n",
      "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "‚àóEqual contribution. ...\n",
      "\n",
      "[3] codegen.pdf ‚Ä¢ p.9\n",
      "to natural language processing (Devlin et al., 2019; Lewis et al., 2020; Raffel et al., 2020), computer\n",
      "vision (Dosovitskiy et al., 2021), and many other areas (Oord et al., 2018; Jumper et al., 2021). Prior\n",
      "works, such as CuBERT (Kanade et al., 2020), CodeBERT (Feng et al., 2020), PyMT5 (Clement et ...\n"
     ]
    }
   ],
   "source": [
    "# STEP 3 - EMBEDDING AND UPLOAD DATA INTO OUR VECTORSTORE\n",
    "\n",
    "# ___________________________________________________________________________ LOCAL VERSION\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "# Build local FAISS index\n",
    "db_FAISS = FAISS.from_documents(\n",
    "    documents=pdf_chunks,\n",
    "    embedding=embeddings,                         # e.g., OpenAIEmbeddings(\"text-embedding-3-small\")\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    ")\n",
    "\n",
    "# Quick check\n",
    "query = \"Who created Transformers?\"\n",
    "\n",
    "matches = db_FAISS.similarity_search(query, k=3)\n",
    "print(f\"We found {len(matches)} similarities.\")\n",
    "for i, m in enumerate(matches, 1):\n",
    "    print(f\"\\n[{i}] {m.metadata.get('citation', m.metadata)}\")\n",
    "    print(m.page_content[:300], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afb3bf-6c25-4562-b9c7-f32d17729cf9",
   "metadata": {},
   "source": [
    "# PART 3: Talking with our documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d54ac1-c3ff-42c3-a9c8-151548914489",
   "metadata": {},
   "source": [
    "## STEP 4 - DEFINE A CHAIN AND PERFORM THE SIMILARITY SEARCH\n",
    "Generating a simple pipeline to query our documents with a load_qa_chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85627ed4-89b0-475c-b7ea-caba04fce893",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1844,
    "lastExecutedAt": 1704819185918,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# 1. Import the load_qa_chain\nfrom langchain.chains.question_answering import load_qa_chain \n\n# 2. Define a prompt of interest. \nquery = \"Can you please tell me all the autors of the article Attention is all you need?\"\n\n# 3. Define the chain\nchain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n\n# 4. Perform a similarity search. \nmatches = db_FAISS.similarity_search(query, k=1)\n\n# 5. Execute the chain to obtain a NLP based response. \nresponse = chain.run(input_documents = matches, question = query)\nprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 227,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors of the paper \"Attention Is All You Need\" are:\n",
      "\n",
      "1. Ashish Vaswani\n",
      "2. Noam Shazeer\n",
      "3. Niki Parmar\n",
      "4. Jakob Uszkoreit\n",
      "5. Llion Jones\n",
      "6. Aidan N. Gomez\n",
      "7. ≈Åukasz Kaiser\n",
      "8. Illia Polosukhin\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Vector store & retriever\n",
    "db = FAISS.from_documents(pdf_chunks, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", k=2)\n",
    "\n",
    "# LLM + prompt\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Use the context to answer the question.\\n\\n{context}\\n\\nQuestion: {input}\"\n",
    ")\n",
    "\n",
    "# Build chains\n",
    "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag = create_retrieval_chain(retriever, doc_chain)\n",
    "\n",
    "# Ask\n",
    "q = \"List all the authors of the paper 'Attention Is All You Need'.\"\n",
    "resp = rag.invoke({\"input\": q})\n",
    "print(resp[\"answer\"])              # final answer\n",
    "# print(resp[\"context\"])           # the retrieved Documents (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ff4a1",
   "metadata": {},
   "source": [
    "Now that we already have a working pipeline to query our documents, we want to understand where our data is coming from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8365e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors of the paper \"Attention Is All You Need\" are:\n",
      "\n",
      "1. Ashish Vaswani\n",
      "2. Noam Shazeer\n",
      "3. Niki Parmar\n",
      "4. Jakob Uszkoreit\n",
      "5. Llion Jones\n",
      "6. Aidan N. Gomez\n",
      "7. ≈Åukasz Kaiser\n",
      "8. Illia Polosukhin\n",
      "\n",
      "**Info Sources:**\n",
      "- PDF: The information is found in the provided citation and author list at the beginning of the document.\n",
      "- Page: The authors are listed on page 1747 of the document (as indicated in the citation).\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Vector store & retriever\n",
    "db = FAISS.from_documents(pdf_chunks, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", k=2)\n",
    "\n",
    "# LLM + prompt\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Use the context to answer the question.\\n\\n{context}\\n\\nQuestion: {input}. Please state info sources (both pdf and page of the pdf found in the beginning of each chunk) in the response\"\n",
    ")\n",
    "\n",
    "# Build chains\n",
    "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag = create_retrieval_chain(retriever, doc_chain)\n",
    "\n",
    "# Ask\n",
    "q = \"List all the authors of the paper 'Attention Is All You Need'.\"\n",
    "resp = rag.invoke({\"input\": q})\n",
    "print(resp[\"answer\"])              # final answer\n",
    "# print(resp[\"context\"])           # the retrieved Documents (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cfc58e-6995-4c1d-85b6-1cf185d480df",
   "metadata": {},
   "source": [
    "Try to ask the model something that is completely out of scope, and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67ed267d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not directly address the problems associated with cooking with olive oil. However, based on general knowledge, some common issues when cooking with olive oil include:\n",
      "\n",
      "1. **Smoke Point**: Olive oil has a lower smoke point compared to some other oils, which means it can start to smoke and break down at lower temperatures. This can affect the flavor of the food and produce harmful compounds.\n",
      "\n",
      "2. **Flavor**: The distinct flavor of olive oil may not be suitable for all dishes, especially those that require a neutral oil.\n",
      "\n",
      "3. **Nutrient Loss**: Cooking at high temperatures can lead to the degradation of some of the beneficial compounds in olive oil, such as antioxidants.\n",
      "\n",
      "4. **Cost**: High-quality extra virgin olive oil can be more expensive than other cooking oils, which may be a consideration for some cooks.\n",
      "\n",
      "5. **Storage**: Olive oil can go rancid if not stored properly, which can affect its taste and health benefits.\n",
      "\n",
      "If you need more specific information or have a different context in mind, please let me know!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Vector store & retriever\n",
    "db = FAISS.from_documents(pdf_chunks, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", k=2)\n",
    "\n",
    "# LLM + prompt\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Use the context to answer the question.\\n\\n{context}\\n\\nQuestion: {input}\"\n",
    ")\n",
    "\n",
    "# Build chains\n",
    "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag = create_retrieval_chain(retriever, doc_chain)\n",
    "\n",
    "# Ask\n",
    "q = \"What are the main problems to cook with olive oil?\"\n",
    "resp = rag.invoke({\"input\": q})\n",
    "print(resp[\"answer\"])              # final answer\n",
    "# print(resp[\"context\"])           # the retrieved Documents (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aeec8e-842f-4505-b895-8818cc7021fb",
   "metadata": {},
   "source": [
    "Try other queries and talk with your documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c4b26ec-dc92-49bc-9955-2516e8a0cca6",
   "metadata": {
    "executionCancelledAt": 1704727738652,
    "executionTime": 49,
    "lastExecutedAt": 1704708572393,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def asking_your_model(query, k):\n    # Define the chain\n    chain = load_qa_chain(chatgpt, chain_type=\"stuff\")\n    #Perform a similarity search. \n    matches = db_FAISS.similarity_search(query, k=k)\n    #We define both the text and the metadata obtain from the semantic search.\n    input_text = [x.page_content for x in matches]\n    input_metadata= [x.metadata for x in matches]\n    #We define a metadata prompt with the metadata and ask the model to explicitily state the source. \n    meta_data_enriching = \"The provided information has been extracted from {0}, please state info sources (both pdf and page) in       the response\".format(input_metadata) \n    #We define an enriched query with the initial prompt and the metadata prompt. \n    enriched_query = query + meta_data_enriching\n    #We execute the chain. \n    response = chain.run(input_documents = matches, question = enriched_query)\n    return response\n    "
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "def asking_your_model(query: str, k: int = 3) -> str:\n",
    "    # 1) Retriever from your FAISS index\n",
    "    retriever = db_FAISS.as_retriever(\n",
    "        search_type=\"mmr\", \n",
    "        search_kwargs={\"k\": k, \"fetch_k\": max(12, 3*k)}\n",
    "    )\n",
    "\n",
    "    # 2) Metadata-aware prompts\n",
    "    doc_prompt = PromptTemplate.from_template(\n",
    "        \"SOURCE: {metadata[source]} | PAGE: {metadata[page]}\\nCONTENT:\\n{page_content}\"\n",
    "    )\n",
    "    chat_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Use ONLY the context below to answer. If it's not in the context, say you don't know.\\n\"\n",
    "        \"After the answer, add a line 'Sources:' listing every SOURCE and PAGE you used.\\n\\n\"\n",
    "        \"{context}\\n\\nQuestion: {input}\"\n",
    "    )\n",
    "\n",
    "    # 3) Build RAG chain with your existing ChatOpenAI instance `chatgpt`\n",
    "    doc_chain = create_stuff_documents_chain(chatgpt, chat_prompt, document_prompt=doc_prompt)\n",
    "    rag = create_retrieval_chain(retriever, doc_chain)\n",
    "\n",
    "    # 4) Ask\n",
    "    resp = rag.invoke({\"input\": query})\n",
    "    return resp[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f08ec0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "def ask(query: str, k: int = 2, db=None, model: str = \"gpt-4o-mini\") -> str:\n",
    "    if db is None:\n",
    "        raise ValueError(\"Pass a FAISS `db` (vector store) built from your chunks.\")\n",
    "\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", k=k)\n",
    "    llm = ChatOpenAI(model=model, temperature=0)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Use the context below to answer the question succinctly and accurately.\\n\\n{context}\\n\\nQuestion: {input}\"\n",
    "    )\n",
    "\n",
    "    doc_chain = create_stuff_documents_chain(llm, prompt)  # uses doc.page_content only\n",
    "    rag = create_retrieval_chain(retriever, doc_chain)\n",
    "\n",
    "    resp = rag.invoke({\"input\": query})\n",
    "    return resp[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64a2c499-6ef6-424d-b58d-fbd571dd0522",
   "metadata": {
    "executionCancelledAt": 1704727738653,
    "executionTime": 2198,
    "lastExecutedAt": 1704708574592,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.chains.question_answering import load_qa_chain \n\n# Check similarity search is working\nquery = \"What is functional correctness?\"\nresponse = asking_your_model(query, k=4)\nprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 97,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functional correctness refers to the evaluation of a program based on its ability to pass a set of predefined unit tests, ensuring that it behaves as intended according to specified requirements. This metric is used to assess the correctness of code generation, particularly in contexts like unsupervised code translation and docstring-conditional code generation, as it aligns with how human developers judge code quality.\n"
     ]
    }
   ],
   "source": [
    "# Check similarity search is working\n",
    "query = \"What is functional correctness?\"\n",
    "response = ask(query, k=4, db=db_FAISS)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6eb01de-7644-45a0-a88c-f290ee351640",
   "metadata": {
    "executionCancelledAt": 1704727738654,
    "executionTime": 3163,
    "lastExecutedAt": 1704708577755,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.chains.question_answering import load_qa_chain \n\n# Check similarity search is working\nquery = \"What is the multi-head attention in a transformer?\"\nresponse = asking_your_model(query, k=4)\nprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 217,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-head attention in a Transformer is a mechanism that allows the model to jointly attend to information from different representation subspaces at various positions. It consists of multiple parallel attention layers, or heads, which process the input data simultaneously. Each head computes attention using its own set of learned projections for queries, keys, and values, enabling the model to capture diverse features and relationships in the data. The outputs from all heads are concatenated and projected to form the final values, enhancing the model's ability to understand complex dependencies in the input and output sequences.\n"
     ]
    }
   ],
   "source": [
    "# Check similarity search is working\n",
    "query = \"What is the multi-head attention in a transformer?\"\n",
    "response = ask(query, k=4, db=db_FAISS)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0925bf69-fc5b-47d8-8f7d-322dab181ae3",
   "metadata": {
    "executionCancelledAt": 1704727738655,
    "executionTime": 3217,
    "lastExecutedAt": 1704708580972,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "from langchain.chains.question_answering import load_qa_chain \n\n# Check similarity search is working\nquery = \"What are the main components of a transformer?\"\nresponse = asking_your_model(query, k=4)\nprint(response)",
    "outputsMetadata": {
     "0": {
      "height": 137,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main components of a Transformer are:\n",
      "\n",
      "1. **Encoder**: Composed of a stack of identical layers (N = 6), each with:\n",
      "   - Multi-head self-attention mechanism\n",
      "   - Position-wise fully connected feed-forward network\n",
      "   - Residual connections and layer normalization around each sub-layer\n",
      "\n",
      "2. **Decoder**: Similar to the encoder, it also consists of stacked layers with self-attention and feed-forward networks, but includes mechanisms to attend to the encoder's output.\n",
      "\n",
      "3. **Attention Mechanism**: Allows modeling of dependencies between input and output sequences without regard to their distance.\n",
      "\n",
      "4. **Residual Connections and Layer Normalization**: Enhance training stability and performance.\n",
      "\n",
      "These components work together to enable parallelization and improve translation quality.\n"
     ]
    }
   ],
   "source": [
    "# Check similarity search is working\n",
    "query = \"What are the main components of a transformer?\"\n",
    "response = ask(query, k=4, db=db_FAISS)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
